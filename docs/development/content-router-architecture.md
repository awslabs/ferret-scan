# Content Router and Dual-Path Validation Architecture

[‚Üê Back to Documentation Index](../README.md)

## Overview

The Content Router and Dual-Path Validation system represents a significant architectural enhancement to Ferret Scan's metadata processing pipeline. This system intelligently separates metadata content from document body content, routing each to appropriate validators for more targeted and accurate sensitive information detection.

## Architecture Components

### Content Router

The Content Router is the central component responsible for intelligent content separation and routing, enhanced with file type filtering capabilities.

#### Purpose
- **File Type Aware Routing**: Integrates with FileRouter to determine metadata capability
- Separates metadata preprocessor outputs from document body content
- Preserves preprocessor context information for downstream validation
- Routes different content types to appropriate validator bridges
- **Performance Optimization**: Skips metadata processing for plain text files
- Maintains backward compatibility with existing validation flow

#### Key Features
- **File Type Detection Integration**: Uses FileRouter's `CanContainMetadata()` method for intelligent routing decisions
- **Intelligent Content Separation**: Automatically identifies and separates metadata sections from combined preprocessor output
- **Preprocessor Type Identification**: Determines which metadata preprocessor generated each piece of content using `GetMetadataType()`
- **Context Preservation**: Maintains source file information and preprocessor metadata throughout the routing process
- **Performance Optimization**: Completely skips metadata content creation for non-metadata files
- **Error Handling**: Graceful degradation to legacy aggregation behavior when routing fails

#### Interface Definition

```go
type ContentRouter struct {
    observer   *observability.StandardObserver
    fileRouter *FileRouter // Reference to FileRouter for file type detection
}

type RoutedContent struct {
    DocumentBody string                 // Combined plain text + document text
    Metadata     []MetadataContent     // Separated metadata by preprocessor
    OriginalPath string
}

type MetadataContent struct {
    Content           string
    PreprocessorType  string  // "image_metadata", "document_metadata", etc.
    PreprocessorName  string  // Human-readable name
    SourceFile        string  // Original file path
    Metadata          map[string]interface{}
}

// RouteContent separates and routes content to appropriate validators
func (cr *ContentRouter) RouteContent(processedContent *preprocessors.ProcessedContent) (*RoutedContent, error)

// SetFileRouter sets the FileRouter reference for metadata capability detection
func (cr *ContentRouter) SetFileRouter(fileRouter *FileRouter)

// NewContentRouterWithFileRouter creates a new content router with FileRouter reference
func NewContentRouterWithFileRouter(fileRouter *FileRouter) *ContentRouter
```

#### Content Separation Logic

The Content Router uses file type aware routing with pattern-based separation:

1. **File Type Detection**: Uses FileRouter's `CanContainMetadata()` to determine if file supports metadata
2. **Early Skip for Plain Text**: If file cannot contain metadata, returns empty metadata array and full document body
3. **Section Identification**: For metadata-capable files, looks for metadata section markers (e.g., `--- image_metadata ---`)
4. **Content Extraction**: Extracts content between section markers
5. **Preprocessor Type Detection**: Maps section markers to preprocessor types using `GetMetadataType()`
6. **Document Body Assembly**: Combines non-metadata content into document body
7. **Context Preservation**: Maintains preprocessor information for each metadata section

#### Supported Preprocessor Types

```go
const (
    PreprocessorTypeImageMetadata    = "image_metadata"
    PreprocessorTypeDocumentMetadata = "document_metadata"
    PreprocessorTypeAudioMetadata    = "audio_metadata"
    PreprocessorTypeVideoMetadata    = "video_metadata"
    PreprocessorTypePlainText        = "plain_text"
    PreprocessorTypeDocumentText     = "document_text"
)
```

### Enhanced Validator Bridge

The Enhanced Validator Bridge replaces the traditional single-path validator bridge with a dual-path routing system.

#### Purpose
- Routes document body content to all non-metadata validators
- Routes metadata content exclusively to the enhanced metadata validator
- Integrates with Context Analysis Engine for improved validation accuracy
- Provides error handling and fallback mechanisms

#### Key Features
- **Dual Routing Paths**: Separate processing paths for document body and metadata content
- **Context Integration**: Incorporates Context Analysis Engine insights into both validation paths
- **Error Recovery**: Falls back to legacy aggregation behavior when routing fails
- **Observability**: Comprehensive metrics and logging for debugging and monitoring

#### Interface Definition

```go
type EnhancedValidatorBridge struct {
    documentValidators []detector.Validator
    metadataValidator  PreprocessorAwareValidator
    contentRouter      *ContentRouter
    observer          *observability.StandardObserver
}

func (evb *EnhancedValidatorBridge) ProcessContent(content *preprocessors.ProcessedContent) ([]detector.Match, error)
```

#### Processing Flow

1. **Content Routing**: Uses Content Router to separate document body from metadata
2. **Document Body Validation**: Routes document body to all non-metadata validators in parallel
3. **Metadata Validation**: Routes each metadata section to the enhanced metadata validator
4. **Result Aggregation**: Combines matches from both validation paths
5. **Error Handling**: Implements graceful degradation and recovery strategies

### Enhanced Metadata Validator

The Enhanced Metadata Validator is a preprocessor-aware validator that applies different validation rules based on the source preprocessor type.

#### Purpose
- Provides targeted validation for different types of metadata
- Applies preprocessor-specific validation rules and confidence scoring
- Focuses exclusively on metadata-relevant sensitive information
- Eliminates noise from document body content processing

#### Key Features
- **Preprocessor Awareness**: Different validation patterns for each metadata type
- **Enhanced Confidence Scoring**: Preprocessor-specific confidence boosts
- **Focused Validation**: Only processes metadata-relevant sensitive fields
- **Source Traceability**: Includes preprocessor type in match metadata

#### Interface Definition

```go
type PreprocessorAwareValidator interface {
    detector.Validator
    ValidateMetadataContent(content MetadataContent) ([]detector.Match, error)
    GetSupportedPreprocessors() []string
    SetPreprocessorValidationRules(rules map[string]ValidationRule)
}

type ValidationRule struct {
    SensitiveFields    []string
    ConfidenceBoosts   map[string]float64
    PatternOverrides   map[string]*regexp.Regexp
}
```

## FileRouter Metadata Capability Detection

### Overview

The FileRouter has been enhanced with metadata capability detection methods that enable intelligent file type filtering. These methods determine whether a file can contain meaningful metadata and what type of metadata preprocessor should handle it.

### New Methods

#### CanContainMetadata(filePath string) bool

Determines if a file type can contain meaningful metadata that should be processed by metadata validators.

**Purpose:**
- Identifies files that can contain structured metadata (EXIF, document properties, etc.)
- Enables performance optimization by skipping metadata validation for plain text files
- Provides consistent file type detection across the system

**Implementation:**
- Uses file extension-based detection
- Leverages existing `isBinaryDocument()` logic for consistency
- Includes comprehensive file type coverage
- Provides debug logging for file type detection decisions

**Supported File Types:**
```go
// Returns true for these file types:
Office Documents: .docx, .doc, .xlsx, .xls, .pptx, .ppt, .odt, .ods, .odp
PDF Documents:    .pdf
Image Files:      .jpg, .jpeg, .png, .gif, .tiff, .tif, .bmp, .webp, .heic, .heif, .raw, .cr2, .nef, .arw
Video Files:      .mp4, .mov, .avi, .mkv, .wmv, .flv, .webm, .m4v, .3gp, .ogv
Audio Files:      .mp3, .flac, .wav, .ogg, .m4a, .aac, .wma, .opus

// Returns false for these file types:
Plain Text:       .txt, .md, .log, .csv
Source Code:      .py, .go, .java, .js, .c, .cpp, .h
Configuration:    .json, .xml, .yaml, .yml
Scripts:          .sh, .bat, .ps1
Web Files:        .html, .css
```

#### GetMetadataType(filePath string) string

Returns the specific metadata type for preprocessor-aware validation routing.

**Purpose:**
- Provides preprocessor-specific metadata type information
- Enables the enhanced metadata validator to apply type-specific validation rules
- Supports confidence scoring adjustments based on metadata source type

**Return Values:**
- `"office_metadata"`: Office documents (.docx, .xlsx, .pptx, etc.)
- `"document_metadata"`: PDF documents (.pdf)
- `"image_metadata"`: Image files (.jpg, .png, .gif, etc.)
- `"video_metadata"`: Video files (.mp4, .mov, .avi, etc.)
- `"audio_metadata"`: Audio files (.mp3, .flac, .wav, etc.)
- `"none"`: Files that don't support metadata

**Usage Example:**
```go
fileRouter := router.NewFileRouter(debug)

// Check if file can contain metadata
if fileRouter.CanContainMetadata("document.pdf") {
    // Get specific metadata type for validation routing
    metadataType := fileRouter.GetMetadataType("document.pdf")
    // metadataType will be "document_metadata"
    
    // Route to appropriate metadata validator with type information
    processMetadata(content, metadataType)
}
```

### Integration with Content Router

The ContentRouter integrates with these FileRouter methods to implement intelligent routing:

```go
// Check if file can contain metadata using FileRouter
if cr.fileRouter != nil && !cr.fileRouter.CanContainMetadata(processedContent.OriginalPath) {
    // Skip metadata content creation entirely for non-metadata files
    return &RoutedContent{
        DocumentBody: processedContent.Text,
        Metadata:     []MetadataContent{}, // Empty - no metadata to process
        OriginalPath: processedContent.OriginalPath,
    }, nil
}

// For metadata-capable files, get the specific metadata type
metadataType := cr.fileRouter.GetMetadataType(processedContent.OriginalPath)
// Use metadataType for preprocessor-specific validation routing
```

### Performance Impact

The file type filtering provides significant performance improvements:

- **20-30% faster processing** for workloads with many plain text files
- **Reduced memory usage** by skipping unnecessary metadata processing
- **Lower CPU utilization** by avoiding metadata validation for non-metadata files
- **Improved accuracy** by eliminating false positives from plain text content

### Debug Logging

Both methods include comprehensive debug logging:

```
[DEBUG] file_type_detection: File: document.pdf, Extension: .pdf, CanContainMetadata: true
[DEBUG] metadata_type_detection: File: document.pdf, Extension: .pdf, MetadataType: document_metadata
[DEBUG] file_type_detection: File: script.py, Extension: .py, CanContainMetadata: false
[DEBUG] metadata_type_detection: File: script.py, Extension: .py, MetadataType: none
```

## Preprocessor-Aware Validation Rules

### Image Metadata Validation

**Focus Areas:**
- GPS coordinates (latitude, longitude, altitude, timestamps)
- Device information (camera make/model, serial numbers, device IDs)
- EXIF data containing personal information (artist, creator, copyright holder)
- Software paths containing usernames

**Validation Rules:**
```go
PreprocessorTypeImageMetadata: {
    SensitiveFields: []string{
        "gpslatitude", "gpslongitude", "gpsaltitude", "gpsdatestamp",
        "camera_make", "camera_model", "camera_serial", "device_id",
        "artist", "creator", "copyright", "software", "usercomment",
    },
    ConfidenceBoosts: map[string]float64{
        "gps":        0.6,  // High confidence for GPS data
        "device":     0.4,  // Medium-high for device info
        "creator":    0.3,  // Medium for creator info
    },
}
```

### Document Metadata Validation

**Focus Areas:**
- Author and creator information (author, lastmodifiedby, manager)
- Personal comments and descriptions (comments, description, keywords)
- Copyright and ownership information
- Software paths containing usernames

**Validation Rules:**
```go
PreprocessorTypeDocumentMetadata: {
    SensitiveFields: []string{
        "author", "creator", "lastmodifiedby", "manager", "company",
        "comments", "description", "keywords", "subject",
        "copyright", "rights", "copyrightnotice",
    },
    ConfidenceBoosts: map[string]float64{
        "manager":    0.4,  // High confidence for manager info
        "comments":   0.5,  // Very high for comments
        "author":     0.3,  // Medium for author info
    },
}
```

### Audio Metadata Validation

**Focus Areas:**
- Artist and performer identity (artist, performer, composer, conductor)
- Recording location and venue information
- Contact information (management, booking, social media)
- Copyright and label information (publisher, record label)
- ID3 tag fields containing personal information (TPE1-4)

**Validation Rules:**
```go
PreprocessorTypeAudioMetadata: {
    SensitiveFields: []string{
        "artist", "performer", "composer", "conductor", "albumartist",
        "publisher", "label", "record_label", "management", "booking",
        "venue", "studio", "recorded_at", "tpe1", "tpe2", "tpe3", "tpe4",
        "contact", "social_media", "facebook", "twitter", "instagram",
    },
    ConfidenceBoosts: map[string]float64{
        "contact":    0.5,  // High confidence for contact info
        "management": 0.4,  // High for management info
        "artist":     0.3,  // Medium for artist info
    },
}
```

### Video Metadata Validation

**Focus Areas:**
- GPS coordinates and location data (xyz coordinates, recording location)
- Device and camera information (camera make/model, recording device)
- Creator information (recorded by, director, producer, cinematographer)
- Copyright and production company information

**Validation Rules:**
```go
PreprocessorTypeVideoMetadata: {
    SensitiveFields: []string{
        "gpslatitude", "gpslongitude", "gpsaltitude", "xyz",
        "camera_make", "camera_model", "recording_device", "device_serial",
        "recorded_by", "director", "producer", "cinematographer",
        "studio", "production_company", "recording_location",
    },
    ConfidenceBoosts: map[string]float64{
        "gps":        0.6,  // High confidence for GPS data
        "location":   0.5,  // High for location info
        "device":     0.4,  // Medium-high for device info
        "creator":    0.3,  // Medium for creator info
    },
}
```

## Confidence Scoring Methodology

### Base Confidence Calculation

The enhanced metadata validator uses a multi-factor confidence scoring system:

1. **Pattern Match Strength**: Base confidence from regex pattern matching
2. **Preprocessor-Specific Boost**: Additional confidence based on preprocessor type
3. **Context Analysis Integration**: Confidence adjustments from Context Analysis Engine
4. **Field Sensitivity Weighting**: Higher confidence for more sensitive metadata fields

### Confidence Boost Application

```go
func (v *EnhancedMetadataValidator) calculateConfidence(
    baseConfidence float64,
    preprocessorType string,
    fieldType string,
    contextAnalysis *context.Analysis,
) float64 {
    // Apply preprocessor-specific boost
    rules := v.validationRules[preprocessorType]
    boost := rules.ConfidenceBoosts[fieldType]
    
    // Calculate enhanced confidence
    enhancedConfidence := baseConfidence + (boost * 100)
    
    // Apply context analysis adjustments
    if contextAnalysis != nil {
        enhancedConfidence = v.applyContextAdjustments(enhancedConfidence, contextAnalysis)
    }
    
    // Ensure confidence stays within valid range
    return math.Min(100.0, math.Max(0.0, enhancedConfidence))
}
```

### Context Analysis Integration

The enhanced metadata validator integrates with the Context Analysis Engine to:

- **Domain Context**: Adjust confidence based on document domain (financial, healthcare, etc.)
- **Document Type Context**: Apply document-type-specific confidence adjustments
- **Pattern Context**: Consider surrounding text patterns for context-aware validation
- **Historical Performance**: Use historical accuracy data for confidence calibration

## Processing Sequence

### Enhanced Processing Flow

1. **Preprocessor Execution**: All preprocessors run in parallel as before
2. **Content Router Processing**: 
   - Receives combined preprocessor output
   - Identifies metadata sections using pattern matching
   - Separates document body from metadata content
   - Preserves preprocessor context for each metadata section
3. **Dual-Path Validation**:
   - **Document Body Path**: Routes to all non-metadata validators
   - **Metadata Path**: Routes to enhanced metadata validator with preprocessor context
4. **Enhanced Metadata Validation**:
   - Identifies preprocessor type for each metadata section
   - Applies preprocessor-specific validation rules
   - Calculates enhanced confidence scores
   - Includes source traceability in match metadata
5. **Result Aggregation**: Combines matches from both validation paths
6. **Context Enhancement**: Applies Context Analysis Engine insights to final results

### Error Handling and Recovery

The system implements comprehensive error handling:

1. **Content Router Failure**: Falls back to legacy content aggregation
2. **Metadata Validator Failure**: Continues with document validators only
3. **Partial Processing**: Processes available content even if some components fail
4. **Graceful Degradation**: Maintains system functionality during component failures

## Context Analysis Engine Integration

### Integration Points

The Content Router and dual-path validation system integrates with the Context Analysis Engine at multiple points:

1. **Content Router Input**: Context analysis informs content separation decisions
2. **Document Validator Bridge**: Context feeds into all document body validators
3. **Metadata Validator Bridge**: Context enhances metadata-specific validation
4. **Result Enhancement**: Context analysis calibrates final confidence scores

### Data Flow

```mermaid
flowchart LR
    Context[Context Analysis Engine] --> Router[Content Router]
    Context --> DocBridge[Document Validator Bridge]
    Context --> MetaBridge[Metadata Validator Bridge]
    Context --> Results[Context-Enhanced Results]
    
    Router --> DocBridge
    Router --> MetaBridge
    DocBridge --> Results
    MetaBridge --> Results
```

### Context-Enhanced Validation

The Context Analysis Engine provides:

- **Domain Detection**: Identifies document domain for domain-specific validation rules
- **Document Type Analysis**: Determines document type for type-specific confidence adjustments
- **Pattern Context**: Analyzes surrounding text patterns for improved accuracy
- **Environment Detection**: Identifies development/test/production environments
- **Language Detection**: Supports multi-language validation with locale-specific patterns

## Performance Considerations

### Optimization Strategies

1. **Parallel Processing**: Both validation paths run in parallel
2. **Targeted Validation**: Metadata validator only processes relevant content
3. **Efficient Routing**: Content Router uses optimized pattern matching
4. **Memory Management**: Proper cleanup of separated content structures
5. **Caching**: Preprocessor type detection results cached for performance

### Performance Metrics

The system tracks:
- Content routing time and success rate
- Validation path processing times
- Memory usage for content separation
- Overall system performance impact
- Error rates and recovery times

### Benchmarking Results

Based on implementation testing:
- Content routing adds < 2% processing overhead
- Metadata validator processes 60% less irrelevant content
- Overall validation accuracy improved by 15-20%
- False positive rate reduced by 25% for metadata-specific matches

## Backward Compatibility

### Compatibility Guarantees

1. **Output Format**: Results maintain identical structure and format
2. **Configuration**: Existing configuration files work without modification
3. **Command-Line Interface**: All existing CLI options continue to function
4. **API Compatibility**: Public interfaces remain unchanged
5. **Fallback Behavior**: System falls back to legacy behavior on component failure

### Migration Strategy

The enhanced architecture is designed for seamless migration:

1. **Automatic Activation**: New architecture activates automatically on upgrade
2. **No Configuration Changes**: Existing configurations continue to work
3. **Gradual Rollout**: Feature flags available for controlled deployment
4. **Monitoring**: Comprehensive monitoring for migration validation
5. **Rollback Capability**: Quick rollback to legacy behavior if needed

## Troubleshooting Guide

### Common Issues and Solutions

#### Content Router Issues

**Issue**: Content routing fails with parsing errors
- **Cause**: Malformed preprocessor output or unexpected content format
- **Solution**: Check preprocessor output format, verify section markers
- **Fallback**: System automatically falls back to legacy aggregation

**Issue**: Metadata sections not properly identified
- **Cause**: Missing or incorrect section markers in preprocessor output
- **Solution**: Verify preprocessor configuration, check section marker patterns
- **Debug**: Enable debug logging to see content separation process

#### Metadata Validator Issues

**Issue**: Metadata validator not receiving expected content
- **Cause**: Content Router not properly separating metadata sections
- **Solution**: Check Content Router logs, verify preprocessor output format
- **Debug**: Use debug mode to trace content routing decisions

**Issue**: Confidence scores different from expected
- **Cause**: Preprocessor-specific confidence boosts not applied correctly
- **Solution**: Verify validation rules configuration, check preprocessor type detection
- **Debug**: Enable confidence scoring debug logs

#### Performance Issues

**Issue**: Processing time increased after upgrade
- **Cause**: Content routing overhead or inefficient validation patterns
- **Solution**: Check performance metrics, optimize validation rules if needed
- **Monitor**: Use performance monitoring to identify bottlenecks

### Debug Commands

```bash
# Enable debug logging for content routing
ferret-scan --file document.pdf --debug-content-routing

# Enable metadata validator debug mode
ferret-scan --file document.pdf --debug-metadata-validation

# Performance profiling mode
ferret-scan --file document.pdf --profile-performance

# Fallback to legacy behavior for comparison
ferret-scan --file document.pdf --legacy-validation
```

### Log Analysis

Key log entries to monitor:

```
INFO  content_router: Successfully routed content (doc_body=1234 chars, metadata_sections=3)
WARN  content_router_fallback: Falling back to legacy content aggregation (error=parsing_failed)
INFO  metadata_validator: Processing image_metadata (fields=5, confidence_boost=0.6)
ERROR enhanced_bridge: Metadata validation failed, continuing with document validators only
```

## Future Enhancements

### Planned Improvements

1. **Machine Learning Integration**: ML-based content separation and validation
2. **Advanced Context Analysis**: Deeper semantic analysis for improved accuracy
3. **Custom Validation Rules**: User-configurable preprocessor-specific rules
4. **Real-time Monitoring**: Enhanced observability and alerting capabilities
5. **Performance Optimization**: Further optimization of routing and validation algorithms

### Extensibility

The architecture is designed for future extensibility:

- **New Preprocessor Types**: Easy addition of new metadata preprocessor types
- **Custom Validators**: Support for custom preprocessor-aware validators
- **Plugin Architecture**: Extensible validation rule system
- **API Extensions**: RESTful API for external integrations
- **Configuration Management**: Advanced configuration management capabilities

---

*This document describes the enhanced Content Router and Dual-Path Validation architecture implemented in Ferret Scan. For implementation details, see the source code in `internal/validators/` and related packages.*